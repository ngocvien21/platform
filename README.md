# platform for big data from spark - hadoop and hive
#Step 1: Build image for spark;
#Step 2: Build image for hadoop;
#Step 3: Build image forhive;
#Step 4: Using docker compose file to run image builded and connect them in a docker network;

#Note: User can custom version of framework
